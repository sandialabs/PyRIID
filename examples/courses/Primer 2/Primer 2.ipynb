{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pyriid](https://user-images.githubusercontent.com/1079118/124811147-623bd280-df1f-11eb-9f3a-a4a5e6ec5f94.png)\n",
    "\n",
    "# PyRIID Primer 2\n",
    "\n",
    "PyRIID (pronounced: PIE-rid) stands for Python-based Radioisotope IDentification (RIID).\n",
    "\n",
    "PyRIID is a Python package intended to streamline the gamma spectrum synthesis and model fitting workflow.\n",
    "\n",
    "**Intended audience:**\n",
    "\n",
    "Potential or current PyRIID users studying gamma spec-related questions who want a more comprehensive demonstration of PyRIID utilities compared to Primer 1.\n",
    "\n",
    "**Assumed background knowledge:**\n",
    "\n",
    "1. Basic understanding of Python and how to install both it and PyRIID\n",
    "2. Familiarity with what a gamma spectrum is and how they are obtained\n",
    "3. How to install GADRAS\n",
    "\n",
    "**Topics not covered in detail:**\n",
    "\n",
    "- Extensive GADRAS details\n",
    "   - Familiarity with the basics of the Detector and Inject tabs in GADRAS is helpful, but not strictly necessary\n",
    "- Model performance metrics, neural network basics, stochastic gradient descent, and related topics\n",
    "\n",
    "**Duration:**\n",
    "\n",
    "When we present the content of this notebook, it takes ~2 hours as there is additional commentary and questions are answered.\n",
    "Going through it on your own and just running the cells will take considerably less time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Seed Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports, constants, and paths\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from riid import (SampleSet, SeedMixer, SeedSynthesizer, StaticSynthesizer,\n",
    "                  read_hdf, read_json, read_pcf)\n",
    "from riid.models import MLPClassifier\n",
    "from riid.visualize import plot_spectra\n",
    "\n",
    "# SNR values for example problem\n",
    "MIN_SNR = 5\n",
    "MAX_SNR = 300\n",
    "\n",
    "# Directories\n",
    "SEED_CONFIGS_DIR = Path(\"./seed_configs/\")\n",
    "assert SEED_CONFIGS_DIR.exists()\n",
    "DATA_DIR = Path(\"./problem_data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Files\n",
    "BASIC_SEED_CONFIG_PATH = SEED_CONFIGS_DIR.joinpath(\"basic.yaml\")\n",
    "ADVANCED_SEED_CONFIG_PATH = SEED_CONFIGS_DIR.joinpath(\"advanced.yaml\")\n",
    "PROBLEM_SEED_CONFIG_PATH = SEED_CONFIGS_DIR.joinpath(\"problem.yaml\")\n",
    "SEEDS_PATH = str(DATA_DIR.joinpath(\"seeds.h5\"))\n",
    "FG_SEEDS_PATH = str(DATA_DIR.joinpath(\"fg_seeds.h5\"))\n",
    "BG_SEEDS_PATH = str(DATA_DIR.joinpath(\"bg_seeds.h5\"))\n",
    "MIXED_BG_SEEDS_PATH = str(DATA_DIR.joinpath(\"mixed_bg_seeds.h5\"))\n",
    "TRAIN_PATH = str(DATA_DIR.joinpath(\"train.h5\"))\n",
    "MODEL_JSON_PATH = str(DATA_DIR.joinpath(\"model.json\"))\n",
    "MODEL_ONNX_PATH = str(DATA_DIR.joinpath(\"model.onnx\"))\n",
    "MODEL_TFLITE_PATH = str(DATA_DIR.joinpath(\"model.tflite\"))\n",
    "IND_TEST_PATH = str(DATA_DIR.joinpath(\"test.h5\"))  # Hold out, not seen in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Basic seed synthesis\"\"\"\n",
    "with open(BASIC_SEED_CONFIG_PATH) as fin:\n",
    "    seed_synth_config = yaml.safe_load(fin)\n",
    "seed_synth = SeedSynthesizer()\n",
    "simple_seeds = seed_synth.generate(seed_synth_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check where PyRIID is looking for GADRAS\"\"\"\n",
    "from riid.gadras.api import GADRAS_INSTALL_PATH\n",
    "\n",
    "print(GADRAS_INSTALL_PATH)\n",
    "\n",
    "# If you have a non-default GADRAS installation, set an environment variable\n",
    "# named \"GADRAS_DIR\" to point to your custom install location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `SampleSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core Pandas `DataFrame`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`spectra` DataFrame: the samples, the gamma spectra\"\"\"\n",
    "simple_seeds.spectra\n",
    "\n",
    "_ = plot_spectra(simple_seeds, in_energy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`sources` DataFrame: the ground truth\"\"\"\n",
    "simple_seeds.sources\n",
    "# simple_seeds.sources.columns  # Note that the columns of `sources` DataFrame are a \"MultiIndex\" to track ground truth at multiple levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`info` DataFrame: additional information describing each sample\"\"\"\n",
    "simple_seeds.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`prediction_probas` DataFrame: predictions made on data, likely differing from `sources`\"\"\"\n",
    "simple_seeds.prediction_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`detector_info` dictionary: information about the detector response function\"\"\"\n",
    "simple_seeds.detector_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Selecting and copying your data\"\"\"\n",
    "seeds = simple_seeds[:]  # Select all samples; how you make a full copy; careful with large datasets...\n",
    "# seeds[0].sources  # select first sample\n",
    "# seeds[:4].sources  # select first 4 samples\n",
    "# seeds[-2:].sources  # select last 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Separating foregrounds from background\"\"\"\n",
    "fg_seeds, bg_seeds = simple_seeds.split_fg_and_bg()\n",
    "\n",
    "print(fg_seeds)\n",
    "print(bg_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Concatenating multiple SampleSets\"\"\"\n",
    "new_seeds = SampleSet()\n",
    "new_seeds.concat([fg_seeds, bg_seeds])\n",
    "\n",
    "print(new_seeds)  # note loss of detector info; no good way to restore them yet\n",
    "print(simple_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get labels\"\"\"\n",
    "seeds.get_labels()  # By default, the isotope level is extracted\n",
    "seeds.get_labels(target_level=\"Isotope\")\n",
    "seeds.get_labels(target_level=\"Category\")\n",
    "seeds.get_labels(target_level=\"Seed\")\n",
    "seeds.get_labels(include_value=True)\n",
    "\n",
    "# More arguments will be explored later as they become relevant\n",
    "# Note: get_predictions() works identically to get_labels(), except it pulls from `prediction_probas` instead of `sources`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Energy calibration information\"\"\"\n",
    "seeds.info  # A lot of noise\n",
    "seeds.info.loc[:, seeds.ECAL_INFO_COLUMNS]  # Better\n",
    "seeds.ecal  # Succinct, but not a DF\n",
    "seeds.get_channel_energies(0)  # Converting channels to energy\n",
    "seeds.get_all_channel_energies()  # Converting channels to energy for all samples\n",
    "new_ecal_seeds = seeds.as_ecal(0, 1000, 0, 0, 0)  # Interpolating spectra to a new energy calibration\n",
    "# Note: if you have a SampleSet with DISPARATE BUT KNOWN energy calibration parameters,\n",
    "#   `as_ecal()` is useful for transforming all the spectra such that they have the same energy calibration.\n",
    "\n",
    "# PyRIID defines energy calibration in the same terms as GADRAS, which uses the Full Range Fraction defined in ANSI N42.42-2006.\n",
    "# However, PyRIID does not currently support deviation pairs.\n",
    "\n",
    "# Plot in channel space\n",
    "IDX = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(simple_seeds.spectra.iloc[IDX], label=\"original\")\n",
    "ax.plot(new_ecal_seeds.spectra.iloc[IDX], label=\"new\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Spectra when plotted using channels\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot in energy space (note that we have cut off our data)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(simple_seeds.get_channel_energies(IDX), simple_seeds.spectra.iloc[IDX], label=\"original\")\n",
    "ax.plot(new_ecal_seeds.get_channel_energies(IDX), new_ecal_seeds.spectra.iloc[IDX], label=\"new\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Spectra when plotted using energy\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Downsampling (AKA down-binning, AKA rebinning into less channels)\"\"\"\n",
    "downsampled_seeds = simple_seeds[:]  # Make a copy, we're about to be destructive\n",
    "downsampled_seeds.downsample_spectra(128)\n",
    "downsampled_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normalization\"\"\"\n",
    "print(simple_seeds.spectra.sum(axis=1))\n",
    "\n",
    "l1_norm_seeds = simple_seeds[:]  # We're about to be destructive again\n",
    "l1_norm_seeds.normalize()  # p=1, L1 norm, dividing each channel by the sum of counts, default, seeds.normalize(p=1)\n",
    "print(l1_norm_seeds.spectra.sum(axis=1))  # No change, seeds are already normalized\n",
    "\n",
    "l2_norm_seeds = simple_seeds[:]\n",
    "l2_norm_seeds.normalize(p=2)  # p=2, L2 norm, dividing each channel by the sum of squared counts\n",
    "print(l2_norm_seeds.spectra.sum(axis=1))\n",
    "\n",
    "# Plot\n",
    "IDX = 3\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(l1_norm_seeds.spectra.iloc[IDX], label=\"L1 normalized\")\n",
    "ax.plot(l2_norm_seeds.spectra.iloc[IDX], label=\"L2 normalized\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# General rule: bounding the range of your data via normalization makes it easier for a model to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SampleSet arithmetic\n",
    "\n",
    "You can only do the following:\n",
    "- gross = fg + bg\n",
    "- fg = gross - bg\n",
    "\n",
    "Despite being strict, it will detect if you have L1-normalized spectra and rescale for you.\n",
    "\"\"\"\n",
    "fg_seeds, bg_seeds = simple_seeds.split_fg_and_bg()\n",
    "# fg_seeds + bg_seeds  # breaks\n",
    "# fg_seeds[0] + fg_seeds[0]  # breaks\n",
    "# bg_seeds[0] + bg_seeds[0]  # breaks\n",
    "# new_ss = fg_seeds[0] + bg_seeds[0]  # works\n",
    "new_ss = fg_seeds + bg_seeds[0]  # works\n",
    "\n",
    "new_ss.spectra.sum(axis=1)  # Spectra still sums 1 due to automatic rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Spectra states and types\n",
    "\n",
    "State: the form in which the spectra exist\n",
    "Type: Background, Foreground, Gross\n",
    "\n",
    "Both are used by PyRIID to track and properly carry out certain operations.\n",
    "\"\"\"\n",
    "simple_seeds.spectra_state, simple_seeds.spectra_type, fg_seeds.spectra_type, bg_seeds.spectra_type, new_ss.spectra_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Seed health\n",
    "\n",
    "Pretty simple as it checks two things:\n",
    "- all spectra sum to 1 (required for later operations)\n",
    "- dead time is not 100% (we don't like dead seeds)\n",
    "\"\"\"\n",
    "simple_seeds.check_seed_health()  # Performs the default check\n",
    "print(simple_seeds.info.dead_time_prop)  # Note: prop = proportion\n",
    "simple_seeds.check_seed_health(dead_time_threshold=0.01)  # You can relax the dead time check. Note how it now fails as intended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Managing sources\n",
    "\n",
    "Tracking ground truth is important and can be a lot of work.\n",
    "You may find yourself managing it yourself if you're loading data from your custom files.\n",
    "\n",
    "The truth is, for better or worse, what you make it when you synthesize data.\n",
    "\"\"\"\n",
    "from riid.data.labeling import label_to_index_element\n",
    "\n",
    "seeds_sources_as_counts = seed_synth.generate(seed_synth_config, normalize_sources=False)\n",
    "\n",
    "# seeds.normalize_sources()\n",
    "# seeds.drop_sources()  # By default, drops background seeds at seed level; can provide your own; normalizes by default\n",
    "# seeds.drop_spectra_with_no_contributors()\n",
    "# seeds.drop_sources_columns_with_all_zeros()\n",
    "\n",
    "# Outside of these functions, you have to manually build and set the sources DataFrame yourself\n",
    "labels = [\"K40\", \"Am241\", \"Ba133\", \"U235\", \"U238\", \"Mo99\", \"Tc99m\", \"WGPu\", \"K40\"]\n",
    "n_samples = len(labels)\n",
    "column_tuples = [label_to_index_element(l, label_level=\"Seed\") for l in labels]\n",
    "columns = pd.MultiIndex.from_tuples(column_tuples, names=SampleSet.SOURCES_MULTI_INDEX_NAMES)\n",
    "\n",
    "sources_df = pd.DataFrame(np.identity(n_samples), columns=columns)\\\n",
    "    .sort_index(axis=1)\\\n",
    "    .T.groupby(level=SampleSet.SOURCES_MULTI_INDEX_NAMES)\\\n",
    "    .sum().T\n",
    "sources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Saving data\"\"\"\n",
    "simple_seeds.to_hdf(\"seeds.h5\", complevel=3)  # Preserves all information; configurable compression only meaningful for large datasets\n",
    "simple_seeds.to_pcf(\"seeds.pcf\")  # Useful for taking to GADRAS\n",
    "simple_seeds.to_json(\"seeds.json\")  # Useful for review processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading data\"\"\"\n",
    "hdf_seeds = read_hdf(\"seeds.h5\")\n",
    "pcf_seeds = read_pcf(\"seeds.pcf\")\n",
    "json_seeds = read_json(\"seeds.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Randomizing injects\"\"\"\n",
    "DETECTORS = [\n",
    "    \"Generic\\\\NaI\\\\3x3\\\\Front\\\\MidScat\",\n",
    "    \"Generic\\\\CZT\\\\1cm-1cm-1cm\",\n",
    "    \"Generic\\\\PVT\\\\2x2\",\n",
    "]\n",
    "\n",
    "with open(ADVANCED_SEED_CONFIG_PATH) as fin:\n",
    "    seed_synth_config = yaml.safe_load(fin)\n",
    "\n",
    "detector_seeds = {}\n",
    "for d in DETECTORS:\n",
    "    seed_synth_config[\"gamma_detector\"][\"name\"] = d\n",
    "    seeds = seed_synth.generate(seed_synth_config, verbose=True)\n",
    "    detector_seeds[d] = seeds\n",
    "    print(seeds)\n",
    "\n",
    "\"\"\"\n",
    "Takeaways:\n",
    "- Detector variation is slow; DRF (.dat) must be updated every time\n",
    "  - PyRIID attempts to return each DRF to its original state, but errors happen--make backups\n",
    "- Source variation is faster in GADRAS 19 utilizes batch inject per foreground source\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Behind the scenes of randomizing injects\"\"\"\n",
    "from riid.gadras.api import validate_inject_config, get_expanded_config\n",
    "\n",
    "with open(ADVANCED_SEED_CONFIG_PATH) as fin:\n",
    "    seed_synth_config = yaml.safe_load(fin)\n",
    "\n",
    "validate_inject_config(seed_synth_config)\n",
    "\n",
    "get_expanded_config(seed_synth_config)\n",
    "\n",
    "# You can set the random seed in the config for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Sources\n",
    "\n",
    "- Use built-in ones\n",
    "- Build your own (1DM/3DM)\n",
    "- Simulate them (GAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Seed mixing\n",
    "\n",
    "More details: https://www.osti.gov/biblio/2335905\n",
    "\n",
    "Nothing is built in to PyRIID to estimate alphas from data,\n",
    "but if you happen to have proportions, it is a pretty straight\n",
    "forward maximum likelihood estimation problem.\n",
    "\"\"\"\n",
    "_, bg_seeds = simple_seeds.split_fg_and_bg()\n",
    "alphas = [1, 3, 3, 3]\n",
    "mixer = SeedMixer(\n",
    "    bg_seeds,\n",
    "    mixture_size=bg_seeds.n_samples,\n",
    "    dirichlet_alpha=alphas,\n",
    ")\n",
    "mixed_bg_seeds = mixer.generate(100)\n",
    "\n",
    "print(mixed_bg_seeds.sources.mean())\n",
    "mixed_bg_seeds.sources.iloc[:, 1].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Another way to visualize mixtures\"\"\"\n",
    "barh_kwargs = {\n",
    "    \"height\": 1.0,\n",
    "    \"edgecolor\": \"black\",\n",
    "    \"linewidth\": 0.5,\n",
    "}\n",
    "bar_x = np.arange(mixed_bg_seeds.n_samples)+1\n",
    "props = mixed_bg_seeds.sources.to_numpy(float)\n",
    "cols = mixed_bg_seeds.sources.columns.get_level_values(\"Seed\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), sharey=True, sharex=True)\n",
    "\n",
    "ax.barh(bar_x, props[:,0], left=0, label=cols[0], **barh_kwargs)\n",
    "ax.barh(bar_x, props[:,1], left=props[:,0], label=cols[1], **barh_kwargs)\n",
    "ax.barh(bar_x, props[:,2], left=props[:,:2].sum(axis=1), label=cols[2], **barh_kwargs)\n",
    "ax.barh(bar_x, props[:,3], left=props[:,:3].sum(axis=1), label=cols[3], **barh_kwargs)\n",
    "\n",
    "ax.set_title(rf\"$\\alpha$ = {alphas}\")\n",
    "ax.set_xlabel(\"Partitions\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((0, mixed_bg_seeds.n_samples))\n",
    "ax.set_ylabel(\"Sample #\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Static synthesis\n",
    "\n",
    "Static synthesis takes your foreground seeds and your background seeds and adds them together, randomly capturing variation in:\n",
    "- live time\n",
    "- signal-to-noise ratio (SNR)\n",
    "- background count rate (effectively)\n",
    "- Poisson fluctuations\n",
    "\n",
    "You can obtain foreground, background, or gross spectra.\n",
    "\"\"\"\n",
    "static_synth = StaticSynthesizer(\n",
    "    samples_per_seed=100,\n",
    "    bg_cps=300.0,\n",
    "    live_time_function=\"uniform\",\n",
    "    live_time_function_args=(0.25, 8),\n",
    "    snr_function=\"log10\",\n",
    "    snr_function_args=(1, 200),\n",
    "    long_bg_live_time=120,  # adjust this to make background subtraction worse\n",
    "    return_fg=True,\n",
    "    return_gross=False,\n",
    ")\n",
    "foregrounds, _ = static_synth.generate(fg_seeds, mixed_bg_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sample our dataset to plot\"\"\"\n",
    "_ = plot_spectra(foregrounds.sample(3), in_energy=True)  # Note the negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inspect the dataset\"\"\"\n",
    "foregrounds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "There are many different models one can fit.\n",
    "In this course, due to limited time, we will fit one type of classifier (with a simple architecture) and study it.\n",
    "The goal is to demonstrate basic principles for training, using, and testing models that are not limited to \"simple\" ones.\n",
    "\n",
    "### Our problem\n",
    "\n",
    "1. Our detector setup is static, parameters defined in our seed config\n",
    "1. Every spectrum we measure will be background subtracted\n",
    "1. We could observe a wide variety of NORM, medical, and industrial sources, unshielded and shielded.\n",
    "   - Ideally, this is informed by an SME and we iteratively improve our model over time as we get more info\n",
    "1. We would like to classify measurements in reasonably detailed terms (we'll target isotope, collapsing specific configurations)\n",
    "1. We want a basis for \"confidence\"\n",
    "1. We would like to characterize some out-of-distribution behavior\n",
    "   1. Did we generalize to SNR change?\n",
    "   1. Did we generalize to OOD sources?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Seeds\"\"\"\n",
    "with open(PROBLEM_SEED_CONFIG_PATH) as fin:\n",
    "    seed_synth_config = yaml.safe_load(fin)\n",
    "seed_synth = SeedSynthesizer()\n",
    "seeds = seed_synth.generate(seed_synth_config, verbose=True)\n",
    "seeds.to_hdf(SEEDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inspect seeds\"\"\"\n",
    "print(f\"Maximum dead time present: {seeds.info.dead_time_prop.max():.4f}\")\n",
    "print(f\"# of distinct seeds:       {seeds.n_samples}\")\n",
    "print(f\"# of distinct isotopes:    {seeds.get_labels().unique().shape[0]}\")\n",
    "_ = plot_spectra(seeds[:7], in_energy=True, target_level=\"Seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split and mix\"\"\"\n",
    "seeds = read_hdf(SEEDS_PATH)\n",
    "# Downsample at the seed stage!  It speeds everything up.\n",
    "seeds.downsample_spectra(128)\n",
    "fg_seeds, bg_seeds = seeds.split_fg_and_bg()\n",
    "fg_seeds.to_hdf(FG_SEEDS_PATH)\n",
    "bg_seeds.to_hdf(BG_SEEDS_PATH)\n",
    "\n",
    "mixer = SeedMixer(\n",
    "    bg_seeds,\n",
    "    mixture_size=bg_seeds.n_samples,\n",
    "    dirichlet_alpha=2,\n",
    ")\n",
    "mixed_bg_seeds = mixer.generate(1)\n",
    "mixed_bg_seeds.to_hdf(MIXED_BG_SEEDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Static synthesis\"\"\"\n",
    "mixed_bg_seeds = read_hdf(MIXED_BG_SEEDS_PATH)\n",
    "fg_seeds = read_hdf(FG_SEEDS_PATH)\n",
    "\n",
    "static_synth = StaticSynthesizer(\n",
    "    samples_per_seed=500,\n",
    "    bg_cps=300,\n",
    "    live_time_function=\"uniform\",\n",
    "    live_time_function_args=(1, 10),\n",
    "    snr_function=\"log10\",\n",
    "    snr_function_args=(MIN_SNR, MAX_SNR),\n",
    "    long_bg_live_time=120,  # adjust this to make background subtraction worse\n",
    "    return_fg=True,\n",
    "    return_gross=False,\n",
    ")\n",
    "\n",
    "foregrounds, _ = static_synth.generate(fg_seeds, mixed_bg_seeds)\n",
    "foregrounds.to_hdf(TRAIN_PATH)\n",
    "\n",
    "static_synth.samples_per_seed //= 4\n",
    "foregrounds, _ = static_synth.generate(fg_seeds, mixed_bg_seeds)\n",
    "foregrounds.to_hdf(IND_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load and pre-process training data\"\"\"\n",
    "def load_and_preprocess_data(path):\n",
    "    \"\"\"This function standardizes how we load and pre-process data,\n",
    "    reducing the chance of a bug later.\n",
    "    \"\"\"\n",
    "    data = read_hdf(path)\n",
    "    data.normalize(p=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "training_data = load_and_preprocess_data(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training\"\"\"\n",
    "model = MLPClassifier(dense_layer_size=64, dropout=0.8)\n",
    "history = model.fit(training_data, target_level=\"Isotope\", epochs=200, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Learning curve\"\"\"\n",
    "from riid.visualize import plot_learning_curve\n",
    "\n",
    "# _ = plot_learning_curve(history.history[\"loss\"], [0])\n",
    "_ = plot_learning_curve(history.history[\"loss\"], history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model architecture summary\"\"\"\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Save model\n",
    "There are a multiple ways to \"save\" a model out as a file:\n",
    "\n",
    "1. JSON: a PyRIID-specific format enabling you to load the model back in with PyRIID later.\n",
    "   This format is useful because all information about the model, including metadata is encapsulated in one place.\n",
    "2. ONNX: Open Neural Network Exchange format, an open format for machine learning models.\n",
    "3. TFLite: TensorFlow lite format, useful for targeting TF runtimes in various places.\n",
    "\"\"\"\n",
    "\n",
    "model.save(MODEL_JSON_PATH)\n",
    "model.to_onnx(MODEL_ONNX_PATH)\n",
    "model.to_tflite(MODEL_TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load model\"\"\"\n",
    "model = MLPClassifier()\n",
    "model.load(MODEL_JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load in-distribution (IND) test data\"\"\"\n",
    "testing_data = load_and_preprocess_data(IND_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predict IND data\"\"\"\n",
    "model.predict(testing_data)\n",
    "testing_data.get_predictions(include_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Score IND test data\"\"\"\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(testing_data.get_labels(),\n",
    "         testing_data.get_predictions(),\n",
    "         average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confusion matrix\"\"\"\n",
    "from riid.visualize import confusion_matrix\n",
    "\n",
    "cm_kwargs = {\n",
    "    \"as_percentage\": True,\n",
    "    \"figsize\": (14, 14),\n",
    "}\n",
    "_ = confusion_matrix(testing_data, **cm_kwargs)  # We should dispel any notion of a \"perfect\" model--this looks good\n",
    "_ = confusion_matrix(testing_data[testing_data.info.snr > 10], **cm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model score vs. SNR\"\"\"\n",
    "from riid.visualize import plot_snr_vs_score\n",
    "\n",
    "_ = plot_snr_vs_score(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Investigate specific Y88 performance and plot\"\"\"\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y88_label_mask = testing_data.get_labels() == \"Y88\"\n",
    "y88_testing_data = testing_data[y88_label_mask]\n",
    "y88_seed_labels = y88_testing_data.get_labels(\"Seed\")\n",
    "unique_y88_seed_labels = y88_seed_labels.unique()\n",
    "for l in unique_y88_seed_labels:\n",
    "    y88_config_testing_data = y88_testing_data[y88_seed_labels == l]\n",
    "    recall = recall_score(\n",
    "        y88_config_testing_data.get_labels(),\n",
    "        y88_config_testing_data.get_predictions(),\n",
    "        average=\"micro\",\n",
    "    )\n",
    "    print(f\"{l} recall = {recall:.4f}\")\n",
    "\n",
    "plot_data = SampleSet()\n",
    "fg_seed_labels = fg_seeds.get_labels(\"Seed\")\n",
    "fg_isotope_labels = fg_seeds.get_labels()\n",
    "plot_data.concat([\n",
    "    fg_seeds[fg_seed_labels == \"Y88,100uC {10,50}\"],\n",
    "    fg_seeds[fg_seed_labels == \"Y88,100uC {26,30}\"],\n",
    "    fg_seeds[fg_isotope_labels == \"Ra226\"],\n",
    "])\n",
    "_ = plot_spectra(plot_data, target_level=\"Seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Investigate Y88 similarity to Ra226\"\"\"\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "y88_seeds = fg_seeds[fg_isotope_labels == \"Y88\"]\n",
    "y88_seed_labels = y88_seeds.get_labels(\"Seed\")\n",
    "y88_spectra = y88_seeds.spectra.to_numpy()\n",
    "target_y88_seed_label = \"Y88,100uC {10,50}\"\n",
    "target_y88_spectrum = fg_seeds[fg_seed_labels == target_y88_seed_label].spectra.to_numpy()[0]\n",
    "\n",
    "ra226_seeds = fg_seeds[fg_isotope_labels == \"Ra226\"]\n",
    "ra226_seed_labels = ra226_seeds.get_labels(\"Seed\")\n",
    "ra226_spectra = ra226_seeds.spectra.to_numpy()\n",
    "\n",
    "def calculate_and_print_jsd(spec1, spec1_label, spec2, spec2_label):\n",
    "    jsd = jensenshannon(spec1, spec2)\n",
    "    print(f\"{spec1_label} <-> {spec2_label}\".ljust(45), f\"= {jsd:.3f}\")\n",
    "\n",
    "for i, l in enumerate(ra226_seed_labels):\n",
    "    calculate_and_print_jsd(target_y88_spectrum, target_y88_seed_label, ra226_spectra[i], l)\n",
    "\n",
    "for i, l in enumerate(y88_seed_labels):\n",
    "    calculate_and_print_jsd(target_y88_spectrum, target_y88_seed_label, y88_spectra[i], l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-distribution (OOD) Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build some post-processing data\"\"\"\n",
    "fg_seeds = read_hdf(FG_SEEDS_PATH)\n",
    "fg_seeds.downsample_spectra(128)\n",
    "# We specifically do NOT want to use `sources` for confidence as we won't have that in practice\n",
    "sample_jsds = testing_data.get_multiclass_jsds(fg_seeds, model.target_level)\n",
    "\n",
    "def multiclass_jsds_to_top_jsd(jsds):\n",
    "    post = []\n",
    "    for d in jsds:\n",
    "        min_key = min(d, key=d.get)\n",
    "        post.append((min_key, d[min_key]))\n",
    "    post_df = pd.DataFrame(post, columns=[\"seed\", \"jsd\"])\n",
    "    return post_df\n",
    "\n",
    "post_df = multiclass_jsds_to_top_jsd(sample_jsds)\n",
    "post_df[\"model_proba\"] = testing_data.prediction_probas.T.groupby(model.target_level).sum().max()\n",
    "post_df[\"snr\"] = testing_data.info.snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model probability vs. SNR\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(post_df.snr, post_df.model_proba)\n",
    "ax.set_xlabel(\"SNR\")\n",
    "ax.set_ylabel(\"Model probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JSD vs. SNR\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(post_df.snr, post_df.jsd)\n",
    "ax.set_xlabel(\"SNR\")\n",
    "ax.set_ylabel(\"JSD (sample vs. top seed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JSD histogram\"\"\"\n",
    "post_df.jsd.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JSD vs. model probability\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(post_df.jsd, post_df.model_proba)\n",
    "ax.set_xlabel(\"JSD\")\n",
    "ax.set_ylabel(\"Model output\")\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlim((0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confidence using an out-of-distribution (OOD) detector (a binary classifier)\n",
    "\n",
    "For an OOD binary classifier, the positive class is OOD and negative class is in-distribution (IND).\n",
    "As such, a false positive (FP) corresponds to calling an IND sample OOD.\n",
    "In practice, we typically only start out knowing the behavior of our model and in-distribution (synthetic) data.\n",
    "Therefore, the OOD detector, at least for now, must be based on observing deviations from IND data, i.e., negative samples (in this context).\n",
    "To do this we threshold on true negative rate (TNR), which is 1 minus our desired false positive rate (which describes OOD samples).\n",
    "\"\"\"\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "N_QUANTILES = 10\n",
    "TARGET_FP_RATE = 0.001\n",
    "TARGET_TNR = 1 - TARGET_FP_RATE\n",
    "SPLINE_K = 2\n",
    "SPLINE_S = 0\n",
    "snrs = post_df.snr\n",
    "jsds = post_df.jsd\n",
    "\n",
    "snr_buckets = pd.qcut(snrs, N_QUANTILES, labels=False)\n",
    "bucket_thresholds = [\n",
    "    np.quantile(np.array(jsds)[snr_buckets == int(i)], TARGET_TNR)\n",
    "    for i in range(N_QUANTILES)\n",
    "]\n",
    "median_snrs = [\n",
    "    np.median(np.array(snrs)[snr_buckets == int(i)])\n",
    "    for i in range(N_QUANTILES)\n",
    "]\n",
    "spline = UnivariateSpline(\n",
    "    median_snrs,\n",
    "    bucket_thresholds,\n",
    "    k=SPLINE_K,\n",
    "    s=SPLINE_S,\n",
    ")  # The spline is a function which takes an SNR and returns the JSD representing our targeted FPR threshold\n",
    "\n",
    "is_ood = jsds > spline(snrs)\n",
    "post_df[\"ood\"] = is_ood\n",
    "print(f\"Target FPR:   {TARGET_FP_RATE:.4f}\")\n",
    "print(f\"Observed FPR: {post_df.ood.sum() / post_df.shape[0]:.4f}\")\n",
    "post_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOD SNR Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate some OOD SNR data.\n",
    "\n",
    "In practical terms, we know very little about positive classes.\n",
    "That is why we almost have to construct the OOD detector using IND samples.\n",
    "But there is some more we can do.\n",
    "\"\"\"\n",
    "mixed_bg_seeds = read_hdf(MIXED_BG_SEEDS_PATH)\n",
    "fg_seeds = read_hdf(FG_SEEDS_PATH)\n",
    "\n",
    "OOD_MIN_SNR = 0.01\n",
    "OOD_MAX_SNR = 1000\n",
    "static_synth = StaticSynthesizer(\n",
    "    samples_per_seed=100,\n",
    "    bg_cps=300,\n",
    "    live_time_function=\"uniform\",\n",
    "    live_time_function_args=(1, 10),\n",
    "    snr_function=\"log10\",\n",
    "    snr_function_args=(OOD_MIN_SNR, OOD_MAX_SNR),\n",
    "    long_bg_live_time=120,  # adjust this to make background subtraction worse\n",
    "    return_fg=True,\n",
    "    return_gross=False,\n",
    ")\n",
    "ood_snr_data, _ = static_synth.generate(fg_seeds, mixed_bg_seeds)\n",
    "ood_snr_data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predict OOD SNR data\"\"\"\n",
    "model.predict(ood_snr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OOD SNR performance\"\"\"\n",
    "f1_score(ood_snr_data.get_labels(), ood_snr_data.get_predictions(), average=\"micro\")  # Things are worse, of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute JSDs\"\"\"\n",
    "ood_snr_data_jsds = ood_snr_data.get_multiclass_jsds(fg_seeds, model.target_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get top JSDs\"\"\"\n",
    "new_post_df = multiclass_jsds_to_top_jsd(ood_snr_data_jsds)\n",
    "new_post_df[\"model_proba\"] = ood_snr_data.prediction_probas.max(axis=1)\n",
    "new_post_df[\"snr\"] = ood_snr_data.info.snr\n",
    "new_post_df[\"ood\"] = (new_post_df.jsd > spline(new_post_df.snr)) | ~new_post_df.snr.between(MIN_SNR, MAX_SNR)\n",
    "print(new_post_df.ood.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot OOD and IND vs. SNR\"\"\"\n",
    "ood_samples = new_post_df[new_post_df.ood]\n",
    "ind_samples = new_post_df[~new_post_df.ood]\n",
    "\n",
    "ALPHA = 0.3\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ood_samples.snr, ood_samples.jsd, color=\"black\", label=\"OOD\", alpha=ALPHA, marker=\"x\")\n",
    "ax.scatter(ind_samples.snr, ind_samples.jsd, color=\"blue\", label=\"IND\", alpha=ALPHA, marker=\".\")\n",
    "ax.vlines([MIN_SNR, MAX_SNR], 0, 1, label=\"IND SNR range\", color=\"red\", linestyle=\"solid\")\n",
    "# Plot spline\n",
    "snr_range = np.logspace(np.log10(MIN_SNR), np.log10(MAX_SNR), num=100)\n",
    "ax.plot(snr_range, spline(snr_range), color=\"red\", linestyle=\"dashed\", label=\"Spline decision threshold\")\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"SNR\")\n",
    "ax.set_ylabel(\"JSD\")\n",
    "ax.set_ylim((new_post_df.jsd.min(), 1))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOD Source Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate OOD source data\"\"\"\n",
    "# Here, we're using individual background components (K, U, T, and Cosmic) as OOD sources\n",
    "mixed_bg_seeds = read_hdf(MIXED_BG_SEEDS_PATH)\n",
    "bg_seeds = read_hdf(BG_SEEDS_PATH)\n",
    "\n",
    "ood_src_data, _ = static_synth.generate(bg_seeds, mixed_bg_seeds)\n",
    "ood_src_data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predict\"\"\"\n",
    "model.predict(ood_src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute JSDs\"\"\"\n",
    "ood_src_data_jsds = ood_src_data.get_multiclass_jsds(fg_seeds, model.target_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get top JSDs\"\"\"\n",
    "new_post_df = multiclass_jsds_to_top_jsd(ood_src_data_jsds)\n",
    "new_post_df[\"model_proba\"] = ood_src_data.prediction_probas.max(axis=1)\n",
    "new_post_df[\"snr\"] = ood_src_data.info.snr\n",
    "new_post_df[\"ood\"] = (new_post_df.jsd > spline(new_post_df.snr)) | ~new_post_df.snr.between(MIN_SNR, MAX_SNR)\n",
    "print(new_post_df.ood.value_counts())  # what??? they should all be OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot OOD and IND vs. SNR\"\"\"\n",
    "ood_samples = new_post_df[new_post_df.ood]\n",
    "ind_samples = new_post_df[~new_post_df.ood]\n",
    "\n",
    "ALPHA = 0.3\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ood_samples.snr, ood_samples.jsd, color=\"black\", label=\"OOD\", alpha=ALPHA, marker=\"x\")\n",
    "ax.scatter(ind_samples.snr, ind_samples.jsd, color=\"blue\", label=\"IND\", alpha=ALPHA, marker=\".\")\n",
    "ax.vlines([MIN_SNR, MAX_SNR], 0, 1, label=\"IND SNR range\", color=\"red\", linestyle=\"solid\")\n",
    "# Plot spline\n",
    "snr_range = np.logspace(np.log10(MIN_SNR), np.log10(MAX_SNR), num=100)\n",
    "ax.plot(snr_range, spline(snr_range), color=\"red\", linestyle=\"dashed\", label=\"Spline decision threshold\")\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"SNR\")\n",
    "ax.set_ylabel(\"JSD\")\n",
    "ax.set_ylim((new_post_df.jsd.min(), 1))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Here we can see that at > ~100 SNR, background components K, U, T, and cosmic reliably fall OOD.\n",
    "# We can also see that each background components diverages differently due to its distinct features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
