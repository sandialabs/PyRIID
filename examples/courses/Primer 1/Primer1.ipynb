{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRIID Primer #1\n",
    "\n",
    "The goal of this notebook is to present a high-level demonstration of each of the primary PyRIID features and simultaneously provide opportunities for the presenter to highlight general challenges and lessons learned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is PyRIID?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pyriid](./images/pyriid_logo.png)\n",
    "\n",
    "PyRIID (pronounced: PIE-rid) stands for Python-based Radioisotope IDentification (RIID).\n",
    "\n",
    "PyRIID is a Python package containing utilities for making radioisotope identification, and related problems easier to study with an emphasis on machine learning approaches.\n",
    "\n",
    "PyRIID is Open Source and freely available to anyone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can I do with PyRIID?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Synthesis gamma spectra\n",
    "2. Fit models\n",
    "3. Visualize results\n",
    "4. Save and load pretty much everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why \"machine learning\" (ML)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ML to fit models that represent relationships between some specific spaced of gamma spectra and *some output*, typically isotopes.\n",
    "Inference with the resulting models is *fast*, and the data generation processes necessary to train the model are also convenient for exploring performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `SampleSet`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our tour of PyRIID by answering the question, \"What is a SampleSet?\"\n",
    "\n",
    "The `SampleSet` is the primary data structure in which we store spectral data and related information.\n",
    "\n",
    "So much of PyRIID is built around the idea of passing around `SampleSet` objects.\n",
    "\n",
    "- Spectra and related info are stored in `SampleSet`s together.\n",
    "- Normalizing spectra?  There are multiple `SampleSet` methods for this.\n",
    "- Mixing spectra? A `SampleSet` goes into the `SeedMixer` and you get a `SampleSet` out.\n",
    "- Want perform inference with a model? Pass its `predict()` method a `SampleSet`.\n",
    "- Where are my model's predictions?  They are in `prediction_probas` property of the `SampleSet` you just gave it.\n",
    "- Visualization functions?  Almost all take one or more `SampleSet`s as input.\n",
    "\n",
    "`SampleSet`s can be saved as either HDF files or PCF's, and read in from either (some restrictions apply in the case of PCF's).\n",
    "\n",
    "**Terminology Disclaimer:**\n",
    "\n",
    "Whenever you see the term \"foreground\" (often shortened to `fg`), you should think of a spectrum containing only source information (sometimes you will see the term \"source\" used interchangeably with \"foreground\").\n",
    "Likewise, \"background\" (often shortened to `bg`) is a spectrum containing counts exclusively from background sources.\n",
    "In this way, the \"foreground\" source is the novel, anomalous presence in our detector's view of its environment.\n",
    "\n",
    "    gross = fg + bg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Synthesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed** Synthesis is where we obtain the pure spectra (think templates) we will use to *seed* other synthesizers.\n",
    "\n",
    "Here's the full process:\n",
    "\n",
    "![full-process](./images/full_process.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic seed synthesis\n",
    "\n",
    "The API for using PyRIID's Seed Synthesis essentially asks you to write a specification for performing one or more injects in terms of the various parameters made available via the GADRAS API.\n",
    "\n",
    "Your seed specification is your model's first set of assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Synthesizing seeds\"\"\"\n",
    "from riid.gadras.api import GADRAS_API_SEEMINGLY_AVAILABLE\n",
    "\n",
    "if GADRAS_API_SEEMINGLY_AVAILABLE:\n",
    "    from riid import SeedSynthesizer\n",
    "    seed_syn = SeedSynthesizer()\n",
    "    # The YAML file defining the seed synthesis specification is ultimately parsed into a dictionary.\n",
    "    # You can also load it yourself and pass in the dictionary instead - this is useful for varying detector parameters!\n",
    "    seeds_ss = seed_syn.generate(\"./spec_nai_few_sources.yaml\")\n",
    "else:\n",
    "    # If you don't have Windows with GADRAS installed, this will use the dummy seeds below which are not actual gamma spectra.\n",
    "    # Another option would be to load a seeds file obtained elsewhere.\n",
    "    from riid import get_dummy_seeds\n",
    "    seeds_ss = get_dummy_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inspecting SampleSets\"\"\"\n",
    "seeds_ss\n",
    "# seeds_ss.spectra\n",
    "# seeds_ss.sources\n",
    "# seeds_ss.info\n",
    "# seeds_ss.prediction_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Separating our background seeds from our foreground seeds.\"\"\"\n",
    "fg_seeds_ss, bg_seeds_ss = seeds_ss.split_fg_and_bg()\n",
    "\n",
    "print(fg_seeds_ss)\n",
    "print(bg_seeds_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting spectra\"\"\"\n",
    "from riid.visualize import plot_spectra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot foreground(s)\n",
    "am241_only_ss = fg_seeds_ss[fg_seeds_ss.get_labels() == \"Am241\"]\n",
    "fig, ax = plot_spectra(\n",
    "    am241_only_ss,\n",
    "    in_energy=True,\n",
    "    figsize=(9.6, 4.8),\n",
    "    ylim=(1e-10, None),\n",
    "    xlim=(0, 1000),\n",
    "    target_level=\"Seed\",\n",
    "    show=False\n",
    ")\n",
    "ax.axvline(59, color=\"green\", label=\"59 KeV\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot background(s)\n",
    "_ = plot_spectra(\n",
    "    bg_seeds_ss,\n",
    "    in_energy=True,\n",
    "    figsize=(9.6, 4.8),\n",
    "    ylim=(1e-5, None),\n",
    "    title=\"Backgrounds\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Mixing\n",
    "\n",
    "In some cases, it makes sense to \"identify\" a spectrum in terms of a dominant or high priority radioisotope - multiclass classification.\n",
    "In other cases, perhaps we would like to identify a spectrum as merely containing zero or more radioisotopes - multilabel classification.\n",
    "And going one step beyond, perhaps there is a desire to actually look at and utilize the radioisotope proportions predicted my a model - label proportion estimation.\n",
    "\n",
    "In either of the latter two cases, PyRIID's `SeedMixer` is useful as a brute-force approach to randomly combine the seeds you give it, with care given to not combine seeds falling within the same isotope.\n",
    "A common, practical need for mixing is to generate backgrounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Seed mixing\"\"\"\n",
    "from riid import SeedMixer\n",
    "\n",
    "mixed_bg_seeds_ss = SeedMixer(\n",
    "    bg_seeds_ss,\n",
    "    mixture_size=3,\n",
    "    dirichlet_alpha=2,\n",
    ").generate(n_samples=10)\n",
    "\n",
    "print(mixed_bg_seeds_ss.sources)\n",
    "_ = plot_spectra(mixed_bg_seeds_ss, in_energy=True, ylim=(1e-5, None), title=\"Backgrounds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Combining SampleSets\"\"\"\n",
    "from riid import SampleSet\n",
    "\n",
    "combined_ss = SampleSet()\n",
    "combined_ss.concat([fg_seeds_ss, mixed_bg_seeds_ss])\n",
    "combined_ss.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Saving and loading SampleSets\"\"\"\n",
    "fg_seeds_ss.to_hdf(\"./fg_seeds.h5\")\n",
    "bg_seeds_ss.to_hdf(\"./bg_seeds.h5\")\n",
    "\n",
    "fg_seeds_ss.to_pcf(\"./fg_seeds.pcf\")\n",
    "bg_seeds_ss.to_pcf(\"./bg_seeds.pcf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Synthesis\n",
    "\n",
    "**Static** Synthesis is where we take our seeds and generate noisy spectra which vary across SNR and live time.\n",
    "\n",
    "The configuration used for Static Synthesis represents yet another set of assumptions one must make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Static Synthesis\"\"\"\n",
    "from riid import StaticSynthesizer\n",
    "\n",
    "static_syn = StaticSynthesizer(\n",
    "    samples_per_seed=100,\n",
    "    bg_cps=300,\n",
    "    live_time_function=\"uniform\",\n",
    "    live_time_function_args=(0.25, 8),\n",
    "    snr_function=\"log10\",\n",
    "    snr_function_args=(0.1, 100),\n",
    "    apply_poisson_noise=True,\n",
    "    return_fg=True,\n",
    "    return_gross=True,\n",
    ")\n",
    "fg_ss, gross_ss = static_syn.generate(fg_seeds_ss, mixed_bg_seeds_ss)  # Note: be sure to use the mixed background seeds!\n",
    "\n",
    "# Adjust ground truth\n",
    "# gross_ss.sources.drop(bg_seeds_ss.sources.columns, axis=1, inplace=True)  # Remove background ground truth to target model focus\n",
    "# gross_ss.normalize_sources()\n",
    "\n",
    "# You can perform sample-wise, channel-wise addition and subtraction between two compatible SampleSets\n",
    "bg_ss = gross_ss - fg_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normalization\"\"\"\n",
    "fg_ss.normalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now that we have data, we can start making models.\n",
    "\n",
    "![gross_bg_model](./images/gross%2Bbg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model fitting\"\"\"\n",
    "from riid.models import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "history = model.fit(fg_ss, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model learning curve\"\"\"\n",
    "from riid.visualize import plot_learning_curve\n",
    "\n",
    "_ = plot_learning_curve(history.history[\"loss\"], history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate some in-distribution data the model has not seen.\"\"\"\n",
    "test_fg_ss, test_gross_ss = static_syn.generate(fg_seeds_ss, bg_seeds_ss)\n",
    "test_fg_ss.normalize()\n",
    "test_gross_ss.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the model!\"\"\"\n",
    "model.predict(test_fg_ss)  # Results are saved in the SampleSet's prediction_probas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate performance metric\"\"\"\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "labels = test_fg_ss.get_labels()\n",
    "predictions = test_fg_ss.get_predictions()\n",
    "f1_score(labels, predictions, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confusion Matrix\"\"\"\n",
    "from riid.visualize import confusion_matrix\n",
    "\n",
    "_ = confusion_matrix(test_fg_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SNR vs. Model Score\"\"\"\n",
    "from riid.visualize import plot_snr_vs_score\n",
    "\n",
    "_ = plot_snr_vs_score(test_fg_ss, xscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Save model\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _delete_if_exists(path: Path):\n",
    "    if path.exists():\n",
    "        path.unlink()\n",
    "\n",
    "model_path_json = Path(\"./model.json\")\n",
    "model_path_tflite = model_path_json.with_suffix(\".tflite\")\n",
    "model_path_onnx = model_path_json.with_suffix(\".onnx\")\n",
    "_delete_if_exists(model_path_json)\n",
    "_delete_if_exists(model_path_tflite)\n",
    "_delete_if_exists(model_path_onnx)\n",
    "\n",
    "model.save(str(model_path_json))\n",
    "model.to_tflite(str(model_path_tflite))\n",
    "model.to_onnx(str(model_path_onnx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Moving detector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models and data we've seen today are intended for scenarios where the detector is static.\n",
    "\n",
    "To utilize for scenarios where the detector is moving, one could swap anomaly detection and identification, leading to a need for a new type of anomaly detection.\n",
    "This approach also necessitates, at minimum, an expansion of the training regimen to cover various background environments.\n",
    "\n",
    "![edge-detection](./images/edge_detection.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many challenges and pitfalls exist:\n",
    "\n",
    "- Deciding on configurations for seed synthesis, seed mixing, and static synthesis, i.e., defining your problem\n",
    "- The typical normalization and hyperparameter choices, however these generally do not seem to require much investigation\n",
    "- Deciding how to compare models trained to different problems (hint: don't)\n",
    "- With synthetic data, performance can be what the creators wants it to be.\n",
    "- Understanding the difference between your training problem space and deployment problem space\n",
    "- Being able to describe your problem space(s) properly\n",
    "    - \"We don't care about all possible worlds, only the one we live in. If we know something about the world and incorporate it into our learner, it now has an advantage over random guessing.\" - The Master Algorithm, 2018\n",
    "    - \"This is of considerable theoretical interest but, I think, of limited practical value, because the space of all possible problems likely includes many extremely unusual and pathological problems which are rarely if ever seen in practice.\" - Essentials of Metaheuristics, 2011\n",
    "- Varying DRF params and mixing seeds *quickly* blows up your problem, and subsuquently trying to model `spectra -> radioisotope` may be problematic without additional knowledge - no free lunch (Wolpert and McCready, 1997).\n",
    "    - \"In the meantime, the practical consequence of the 'no free lunch' theorem is that there's no such thing as learning without knowledge. Data alone is not enough.\" - The Master Algorithm, 2018\n",
    "- **Build trust in this technology, like you do any other technology, by spending time with it and evaluating it.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics We Didn't Get To"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Demonstration of large-scale DRF parameter variation - it takes a long time :(\n",
    "- Models that take other models as input\n",
    "- Multi-isotope\n",
    "- Alternative normalization methods\n",
    "- Alternative visualization methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- Repository: https://github.com/sandialabs/pyriid\n",
    "- Releases: https://github.com/sandialabs/pyriid/releases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv_3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bf1d4e9156faded57533a51ba24099c8163631c7dea882fcb0730e050bfcf6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
